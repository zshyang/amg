log_dir: "../_runtime/temp_dir"
temp_dir: "../_runtime/save_dir"

# resolution: [256, 256]
# vit_resolution: [224, 224]
num_steps: 1000000
sample_fps: 8
max_frames: 16

use_fp16: true

batch_sizes: { "1": 16, "4": 8, "8": 4, "16": 8, "24": 1, "32": 1 }
num_workers: 48

guide_scale: 3.0

concat_input: true
weight_decay: 0.0

Pretrain:
  {
    "resume_checkpoint": "../_runtime/models/model_scope_v1-4_0600000.pth",
    "pretrained_image_keys": "data/stable_diffusion_image_key_temporal_attention_x1.json",
    "fix_weight": False,
  }

grad_scale: {
    "spatial": 1, # For LoRA, we do not specify the learning rate like ModelScope.
    "temporal": 1,
  }

embedder:
  {
    "type": "FrozenOpenCLIPEmbedderZero",
    "layer": "penultimate",
    "pretrained": "../_runtime/models/stable-diffusion-v/open_clip_pytorch_model.bin",
  }

vid_dataset:
  {
    "type": "GHVideoFeatureDataset",
    "captions_y_dir": "../_data/processed/captions_y",
    "images_feature_dir": "../_data/processed/images_feature",
    "gh_images_feature_dir": "../_data/processed/gh_images_feature",
    "zero_y_path": "../_data/processed/zero_y.pt",
    "use_small_batch": false,
  }

UNet: {
    "in_dim": 4,
    "dim": 320,
    "y_dim": 1024,
    "context_dim": 1024,
    "out_dim": 4,
    "dim_mult": [1, 2, 4, 4],
    "num_heads": 8,
    "head_dim": 64,
    "num_res_blocks": 2,
    "attn_scales": [1.0, 0.5, 0.25],
    "dropout": 0.1,
    "temporal_attention": True,
    "temporal_attn_times": 1,
    "use_checkpoint": True,
    "use_fps_condition": False,
    "use_sim_mask": False,
    "use_lora": true, # =======================================================
    "lora_rank": 4,
    "lora_alpha",
  }

Diffusion:
  {
    "schedule": "linear_sd",
    "schedule_param":
      {
        "num_timesteps": 1000,
        "init_beta": 0.00085,
        "last_beta": 0.0120,
        "zero_terminal_snr": False,
      },
    "mean_type": "eps",
    "loss_type": "mse",
    "var_type": "fixed_small",
    "rescale_timesteps": False,
    "noise_strength": 0.,
  }

auto_encoder: { "pretrained": "../_runtime/models/v2-1_512-ema-pruned.ckpt" }

ddim_timesteps: 20
ddim_steps:
  [
    951,
    901,
    851,
    801,
    751,
    701,
    651,
    601,
    551,
    501,
    451,
    401,
    351,
    301,
    251,
    201,
    151,
    101,
    51,
    1,
  ]

viz_interval: 200
save_ckp_interval: 1000

visual_train: { "type": "VisualVideoTextDuringTrainUnClip" }
share_noise: False
lr: 0.000001

warmup_steps: 10
decay_mode: "cosine"

use_div_loss: False
